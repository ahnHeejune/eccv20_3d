\section{Introduction}


Online fashion market has been growing rapidly every year. Unlike electronics, which makes it easy to standardize functions and performances, fashion apparels have infinite variations in style, forms, colors, texture, and materials.  Also the difference between personal preferences is huge. As a result, clothing purchasing decisions are very difficult to make with current non-customized information, like the cloth and models' try fit images. Therefore, virtual try-on (VTON) is a highly demanding technology for the online shopping. 

The early VTON technologies were based on 3D computer graphics technology that uses 3D models for a target human and clothing, which are usually expensive and difficult to obtain. Therefore, recently 2D image-based VTON technologies are being studied in academia and industry, fueled by the recent advances in computer vision technologies based on deep learning (DL). 

There have been many assumptions in problem settings from the general conditional human image generation related to VTON application. We consider the one with a try-on cloth and target human image is a practical condition which is assumed in many papers VITON\cite{Han2017VITONAI}, CP-VTON\cite{Wang2018TowardCI} , and the the following  \cite{Sun2019ImageBasedVT,Yu_2019_ICCV}. Therefore we also consider the VTON problem that use the try-on cloth and human images and generated a new virtual image that the target human replaced the current top or bottom cloth with the try-on cloth. In this paper we limit our application to top cloth only due to the restricted data set but consider the bottom, e.g. pants cases would be easier than top cloth cases.

The existing image based algorithms seemingly generate high quality VTON images, but our classified analysis on the cloth styles, and human poses and shapes reveals significant problems[  ]. One reason of the seemingly high quality in the existing algorithms are mainly due to the low complexity of the dataset, i.e., most clothes are short-sleeved, and mono-colored, and the poses of humans are mild. Specifically the results with the long-sleeved cloth arm and body posed shows far low quality of the presented result in their papers. We identified 5 issues in CP-VTON\cite{Wang2018TowardCI} algorithms, some of which are tackled in the following papers. Firstly, the target try-on area is dependent upon current cloth shape. Especially, the neck area pixels are labeled as background and some body areas are occluded by hairs or accessories (Fig. 3 (a) left), which affects in cloth warping and blending. Secondly, all the unintended part, faces, bottom-clothes and legs have to be preserved in blending stage. But other parts except face and hair are missing in CP-VTON\cite{Wang2018TowardCI} human representation and generated at blending stage, which is all right for general synthesis application but not desirable in VTON application (Fig. 3 (b) left). Thirdly, the texture is often not vivid, which is due to the composition. Examining the original loss function of TON network, the term for the composition alpha mask are poorly formulated as simple regularization loss.   

\begin{equation}
L = c_1 | I_0-I_{GT} |+  c_2 L_{VGG}+c_3 |1-M_0 |        
\end{equation} 

Fourthly, since no label in the area of warped cloth is the same color as background, white colored clothes are confused and improperly processed in the blending stage (Fig. 3 (c))
Finally, GMM module using Spatial Transform Network\cite{JaderbergSZK15} with TPS (Thin Plate Spline)\cite{Bookstein1989PrincipalWT} deformation cannot handle strong 3D deformation due to the target pose and also generates artifacts because of the person representation inputs. For example, hands-up and folded arms.  Note that many errors in the warping stage are often hidden in the blending stage when the target clothes are single-colored, which can be expected in practical conditions (Fig. 3 (d)).

In this paper, we focus on the last but most difficult problems that cannot be solved in pure 2D image-based algorithm. The 3D cloth deformation is inherently difficult for 2D warping method, including non-rigid one, like TPS algorithm, we propose to first reconstruct 3D model of try-on cloth, then apply the pose and shape transfer for the target human, and finally blending with unchanged image contents like the face, bottom cloth, and background. Therefore, one of main the tasks now is to reconstruct 3D cloth model from 2D try-on cloth image. The 3D cloth model reconstruction have been studied in previous studies [    ] but still needs significant improvement for general condition. Our key idea in this step is that once we can control the human pose and shape to become similar to the try-on cloth's, the 3D reconstruction process can be made much easier and the reconstruction quality would be much higher than general pose and shape condition. 

So in the Section \ref{section:3dclothrecon}, we describe the 3D cloth reconstruction algorithm. we divide the reconstruction step into 2D matching of cloth to the standard body silhouette and 3D reconstruction of cloth. The later 3D reconstruction step is done through the SMPLify\cite{Bogo2016SMPLify} algorithm for the SMPL 3D body model\cite{Loper2015SMPLAS}.  In Section 4, the blending method described, where the 3D cloth model are transferred to the target human images, through SMPL body parameters of shapes and poses. Then the transferred 3D is rendered and blended to the target human image. In this step we reused the 2D VTON blending algorithm with the modification for the condition.  The sampled results from dataset are presented in Section 5 and the paper is concluded in Section 6. In addition to our main study, we added the classified quality evaluation of the previous 2D image based VTON algorithms for the  completeness of the paper.


